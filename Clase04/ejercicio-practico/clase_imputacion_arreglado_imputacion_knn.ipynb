{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andru-1987/74235-_DataScience_I/blob/main/clase_4/ejercicio-practioco/clase_imputacion_arreglado_imputacion_knn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ejercicio Pr√°ctico: Imputaci√≥n de Datos con KNN\n",
        "\n",
        "## üéØ Objetivo del Ejercicio\n",
        "\n",
        "Este ejercicio pr√°ctico tiene como objetivo:\n",
        "\n",
        "1. **Entender el problema de datos faltantes**: Aprender a identificar y cuantificar valores nulos en un dataset real\n",
        "2. **Comparar m√©todos de imputaci√≥n**: Ver las diferencias entre imputaci√≥n simple (media/moda) y m√©todos avanzados (KNN)\n",
        "3. **Implementar imputaci√≥n KNN**: Aprender a usar KNNImputer de scikit-learn para imputar valores faltantes de manera inteligente\n",
        "4. **Evaluar resultados**: Comparar las distribuciones de datos antes y despu√©s de la imputaci√≥n\n",
        "\n",
        "## üìã ¬øQu√© se busca lograr?\n",
        "\n",
        "- **Clase MarketStore**: Crear una clase que encapsule todo el proceso de an√°lisis e imputaci√≥n de datos\n",
        "- **An√°lisis exploratorio**: Visualizar qu√© columnas tienen valores nulos y en qu√© porcentaje\n",
        "- **Imputaci√≥n inteligente**: Usar KNN (K-Nearest Neighbors) para imputar valores bas√°ndose en registros similares\n",
        "- **Validaci√≥n visual**: Comparar distribuciones antes y despu√©s para verificar que la imputaci√≥n es adecuada\n",
        "\n",
        "## üîë Conceptos Clave\n",
        "\n",
        "- **KNN Imputation**: Encuentra los K registros m√°s similares y usa sus valores para imputar los faltantes\n",
        "- **Label Encoding**: Convierte variables categ√≥ricas a num√©ricas para que KNN pueda trabajar con ellas\n",
        "- **Distribuci√≥n de datos**: Es importante que la imputaci√≥n no distorsione la distribuci√≥n original de los datos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ Importaci√≥n de Librer√≠as\n",
        "\n",
        "Las librer√≠as necesarias para este ejercicio:\n",
        "- **numpy**: Operaciones num√©ricas\n",
        "- **pandas**: Manipulaci√≥n de DataFrames\n",
        "- **matplotlib**: Visualizaciones\n",
        "- **KNNImputer**: Algoritmo de imputaci√≥n basado en vecinos m√°s cercanos\n",
        "- **LabelEncoder**: Convierte variables categ√≥ricas a num√©ricas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Dataset de Ejemplo (Pima Indians Diabetes)\n",
        "\n",
        "Este es un dataset de ejemplo para entender la estructura. El dataset principal que usaremos es el de Market Store.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSpByUBPDzDe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VR38XnOZAQwH"
      },
      "outputs": [],
      "source": [
        "URL_DATASET = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZEb_EsgD6sR"
      },
      "outputs": [],
      "source": [
        "dataframe = pd.read_csv(URL_DATASET)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèóÔ∏è Clase MarketStore: Sistema de An√°lisis e Imputaci√≥n\n",
        "\n",
        "Esta clase encapsula todo el proceso de trabajo con datos faltantes:\n",
        "\n",
        "### M√©todos principales:\n",
        "\n",
        "1. **`get_dataframe()`**: Carga el dataset desde la URL\n",
        "2. **`get_information()`**: Muestra informaci√≥n general del dataset\n",
        "3. **`nullish_counting()`**: Visualiza el porcentaje de valores nulos por columna\n",
        "4. **`imputar_manual()`**: Imputaci√≥n simple usando media (num√©ricas) y moda (categ√≥ricas)\n",
        "5. **`imputacion_knn_imputer()`**: Imputaci√≥n avanzada usando KNN\n",
        "6. **`plot_distribution()`**: Visualiza la distribuci√≥n de una columna antes de imputar\n",
        "7. **`plot_distribution_knn()`**: Visualiza la distribuci√≥n despu√©s de imputar con KNN\n",
        "\n",
        "### ¬øPor qu√© usar una clase?\n",
        "\n",
        "- **Organizaci√≥n**: Todo el c√≥digo relacionado est√° en un solo lugar\n",
        "- **Reutilizaci√≥n**: Puedes aplicar los mismos m√©todos a diferentes datasets\n",
        "- **Mantenibilidad**: Es m√°s f√°cil modificar y extender el c√≥digo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "n8el_oYLD_zg",
        "outputId": "962f87d1-0d06-449c-dc34-a03ac7eea60e"
      },
      "outputs": [],
      "source": [
        "dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Uso de la Clase MarketStore\n",
        "\n",
        "Ahora vamos a usar la clase para analizar el dataset de Market Store.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Paso 1: Cargar el Dataset\n",
        "\n",
        "Cargamos el dataset desde la URL. Este dataset contiene informaci√≥n de productos de una tienda.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Paso 2: Explorar el Dataset\n",
        "\n",
        "Descomenta las siguientes l√≠neas para ver:\n",
        "- Informaci√≥n general del dataset\n",
        "- Porcentaje de valores nulos por columna\n",
        "- Distribuciones de variables espec√≠ficas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9Ic35nXEG1D",
        "outputId": "ffbd910f-48a9-4a1e-cbee-e36d78fb7b2c"
      },
      "outputs": [],
      "source": [
        "dataframe.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Paso 3: Imputaci√≥n con KNN\n",
        "\n",
        "Aplicamos la imputaci√≥n KNN. Este m√©todo:\n",
        "1. Codifica variables categ√≥ricas a num√©ricas\n",
        "2. Encuentra los K vecinos m√°s cercanos para cada registro con valores faltantes\n",
        "3. Usa los valores de esos vecinos para imputar\n",
        "4. Decodifica las variables categ√≥ricas de vuelta a sus valores originales\n",
        "\n",
        "**Par√°metro n_neighbors=4**: Usa los 4 registros m√°s similares para imputar cada valor faltante.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZP1fv9eEVBg"
      },
      "outputs": [],
      "source": [
        "MARKET_STORE_URL = \"https://raw.githubusercontent.com/Andru-1987/csv_files_ds/refs/heads/main/market_data.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxiA19zRFCYW"
      },
      "outputs": [],
      "source": [
        "class MarketStore:\n",
        "    \"\"\"\n",
        "    Clase para analizar e imputar valores faltantes en datasets de tiendas.\n",
        "    \n",
        "    Esta clase proporciona m√©todos para:\n",
        "    - Cargar y explorar datos\n",
        "    - Visualizar valores faltantes\n",
        "    - Imputar valores usando m√©todos simples (media/moda) o avanzados (KNN)\n",
        "    - Comparar distribuciones antes y despu√©s de la imputaci√≥n\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, url):\n",
        "        \"\"\"\n",
        "        Inicializa la clase con la URL del dataset.\n",
        "        \n",
        "        Args:\n",
        "            url: URL del archivo CSV a cargar\n",
        "        \"\"\"\n",
        "        self.url = url\n",
        "        self.dataframe = None  # Dataset original\n",
        "        self.dataframe_imputed_knn = None  # Dataset despu√©s de imputaci√≥n KNN\n",
        "\n",
        "    def get_dataframe(self):\n",
        "        \"\"\"\n",
        "        Carga el dataset desde la URL y lo almacena en self.dataframe.\n",
        "        \n",
        "        Returns:\n",
        "            DataFrame: El dataset cargado\n",
        "        \"\"\"\n",
        "        self.dataframe = pd.read_csv(self.url)\n",
        "        return self.dataframe\n",
        "\n",
        "    def get_information(self):\n",
        "        \"\"\"\n",
        "        Muestra informaci√≥n general del dataset:\n",
        "        - Primeros registros\n",
        "        - Informaci√≥n de columnas y tipos de datos\n",
        "        - Estad√≠sticas descriptivas\n",
        "        \n",
        "        √ötil para entender la estructura y calidad de los datos.\n",
        "        \"\"\"\n",
        "        print(\"\\n=== Informaci√≥n de los primeros registros ===\")\n",
        "        print(self.dataframe.head())\n",
        "        print(\"\\n=== Informaci√≥n sobre columnas y valores nulos ===\")\n",
        "        print(self.dataframe.info())\n",
        "        print(\"\\n=== Informaci√≥n estad√≠stica de los datos ===\")\n",
        "        print(self.dataframe.describe().transpose())\n",
        "\n",
        "    def nullish_counting(self):\n",
        "        \"\"\"\n",
        "        Visualiza el porcentaje de valores nulos por columna.\n",
        "        \n",
        "        ¬øPor qu√© es importante?\n",
        "        - Identifica qu√© columnas tienen m√°s problemas de datos faltantes\n",
        "        - Ayuda a decidir qu√© columnas necesitan imputaci√≥n\n",
        "        - Permite priorizar el trabajo seg√∫n la gravedad del problema\n",
        "        \"\"\"\n",
        "        total_rows = len(self.dataframe)\n",
        "        # Calcula el porcentaje de valores nulos por columna\n",
        "        null_percentage = (self.dataframe.isnull().sum() / total_rows) * 100\n",
        "        # Ordena de mayor a menor porcentaje\n",
        "        null_percentage_sorted = null_percentage.sort_values(ascending=False)\n",
        "\n",
        "        # Visualizaci√≥n\n",
        "        plt.figure(figsize=(16, 9))\n",
        "        ax = null_percentage_sorted.plot(kind='bar', color=\"skyblue\")\n",
        "        ax.set_xlabel(\"Columnas\", fontsize=12)\n",
        "        ax.set_ylabel(\"Porcentaje de valores nulos (%)\", fontsize=12)\n",
        "        ax.set_title(\"Porcentaje de valores nulos por columna\", fontsize=14, fontweight='bold')\n",
        "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
        "        plt.grid(axis='y', alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def imputar_manual(self):\n",
        "        \"\"\"\n",
        "        Imputaci√≥n simple usando m√©todos b√°sicos:\n",
        "        - Variables categ√≥ricas: Se imputan con la moda (valor m√°s frecuente)\n",
        "        - Variables num√©ricas: Se imputan con la media\n",
        "        \n",
        "        ‚ö†Ô∏è Limitaciones:\n",
        "        - No considera relaciones entre variables\n",
        "        - Puede distorsionar la distribuci√≥n de los datos\n",
        "        - No es ideal para datasets con muchas variables correlacionadas\n",
        "        \n",
        "        Este m√©todo modifica directamente self.dataframe.\n",
        "        \"\"\"\n",
        "        # Para variables categ√≥ricas: usar moda (valor m√°s frecuente)\n",
        "        for col in self.dataframe.select_dtypes(include=['object']).columns:\n",
        "            # mode()[0] obtiene el valor m√°s frecuente\n",
        "            self.dataframe[col].fillna(self.dataframe[col].mode()[0], inplace=True)\n",
        "\n",
        "        # Para variables num√©ricas: usar media\n",
        "        for col in self.dataframe.select_dtypes(include=['number']).columns:\n",
        "            self.dataframe[col].fillna(self.dataframe[col].mean(), inplace=True)\n",
        "\n",
        "    def imputacion_knn_imputer(self, n_neighbors=4):\n",
        "        \"\"\"\n",
        "        Imputaci√≥n avanzada usando K-Nearest Neighbors (KNN).\n",
        "        \n",
        "        ¬øC√≥mo funciona KNN Imputation?\n",
        "        1. Para cada registro con valores faltantes, encuentra los K registros m√°s similares\n",
        "        2. Usa los valores de esos K vecinos para imputar el valor faltante\n",
        "        3. Considera todas las variables, no solo la que tiene el valor faltante\n",
        "        \n",
        "        Ventajas sobre imputaci√≥n simple:\n",
        "        - Considera relaciones entre variables\n",
        "        - Mantiene mejor la distribuci√≥n original de los datos\n",
        "        - M√°s preciso cuando hay correlaciones entre variables\n",
        "        \n",
        "        Args:\n",
        "            n_neighbors: N√∫mero de vecinos m√°s cercanos a considerar (default: 4)\n",
        "        \n",
        "        El resultado se guarda en self.dataframe_imputed_knn\n",
        "        \"\"\"\n",
        "        # Paso 1: Copiar el dataset original para no modificar el original\n",
        "        df_encoder = self.dataframe.copy()\n",
        "        encoders = {}  # Guardar√° los encoders para poder decodificar despu√©s\n",
        "\n",
        "        # Paso 2: Detectar y codificar variables categ√≥ricas\n",
        "        # KNN solo funciona con n√∫meros, as√≠ que necesitamos convertir categor√≠as a n√∫meros\n",
        "        category_columns = df_encoder.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "        for col in category_columns:\n",
        "            print(f\"Codificando columna categ√≥rica: {col}\")\n",
        "            le = LabelEncoder()\n",
        "            \n",
        "            # Crear m√°scara para valores no nulos (solo codificar valores existentes)\n",
        "            not_null_values = df_encoder[col].notnull()\n",
        "            \n",
        "            # Codificar solo los valores no nulos\n",
        "            df_encoder.loc[not_null_values, col] = le.fit_transform(\n",
        "                df_encoder.loc[not_null_values, col]\n",
        "            ).astype(str)\n",
        "            \n",
        "            # Mantener los NaN como NaN (no codificarlos)\n",
        "            df_encoder.loc[~not_null_values, col] = np.nan\n",
        "            \n",
        "            # Guardar el encoder para poder decodificar despu√©s\n",
        "            encoders[col] = le\n",
        "\n",
        "        # Paso 3: Aplicar KNN Imputation\n",
        "        # KNNImputer encuentra los n_neighbors registros m√°s similares y usa sus valores\n",
        "        print(f\"\\nAplicando KNN Imputation con {n_neighbors} vecinos...\")\n",
        "        imputer = KNNImputer(n_neighbors=n_neighbors)\n",
        "        data_imputed = imputer.fit_transform(df_encoder)\n",
        "        self.dataframe_imputed_knn = pd.DataFrame(data_imputed, columns=df_encoder.columns)\n",
        "\n",
        "        # Paso 4: Decodificar variables categ√≥ricas de vuelta a sus valores originales\n",
        "        df_decoded = self.dataframe_imputed_knn.copy()\n",
        "        for col, le in encoders.items():\n",
        "            if col in df_decoded.columns:\n",
        "                print(f\"Decodificando columna categ√≥rica: {col}\")\n",
        "                # Convertir de vuelta a enteros y luego decodificar\n",
        "                df_decoded[col] = le.inverse_transform(df_decoded[col].astype(int))\n",
        "\n",
        "        self.dataframe_imputed_knn = df_decoded\n",
        "        print(\"\\n‚úÖ Imputaci√≥n KNN completada!\")\n",
        "\n",
        "    def plot_distribution(self, columna):\n",
        "        \"\"\"\n",
        "        Visualiza la distribuci√≥n de una columna ANTES de la imputaci√≥n.\n",
        "        \n",
        "        Para variables num√©ricas muestra:\n",
        "        - Boxplot: Detecta outliers y muestra cuartiles\n",
        "        - Histograma: Muestra la forma de la distribuci√≥n\n",
        "        \n",
        "        Para variables categ√≥ricas muestra:\n",
        "        - Gr√°fico de barras: Frecuencia de cada categor√≠a\n",
        "        \n",
        "        Args:\n",
        "            columna: Nombre de la columna a visualizar\n",
        "        \"\"\"\n",
        "        if pd.api.types.is_numeric_dtype(self.dataframe[columna]):\n",
        "            plt.figure(figsize=(16, 9))\n",
        "            \n",
        "            # Boxplot: muestra mediana, cuartiles y outliers\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.boxplot(self.dataframe[columna].dropna())\n",
        "            plt.title(f'Boxplot de {columna} (ANTES de imputaci√≥n)', fontweight='bold')\n",
        "            plt.ylabel('Valores')\n",
        "            \n",
        "            # Histograma: muestra la distribuci√≥n\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.hist(self.dataframe[columna].dropna(), bins=20, edgecolor='k', alpha=0.7)\n",
        "            plt.title(f'Histograma de {columna} (ANTES de imputaci√≥n)', fontweight='bold')\n",
        "            plt.xlabel('Valores')\n",
        "            plt.ylabel('Frecuencia')\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "        else:\n",
        "            # Para variables categ√≥ricas: gr√°fico de barras\n",
        "            plt.figure(figsize=(16, 9))\n",
        "            self.dataframe[columna].value_counts().plot(kind='bar')\n",
        "            plt.title(f'Frecuencia de {columna} (ANTES de imputaci√≥n)', fontweight='bold')\n",
        "            plt.xlabel(columna)\n",
        "            plt.ylabel('Frecuencia')\n",
        "            plt.xticks(rotation=45)\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "    def plot_distribution_knn(self, columna):\n",
        "        \"\"\"\n",
        "        Visualiza la distribuci√≥n de una columna DESPU√âS de la imputaci√≥n KNN.\n",
        "        \n",
        "        Permite comparar con plot_distribution() para verificar que:\n",
        "        - La distribuci√≥n no se distorsion√≥ demasiado\n",
        "        - Los valores imputados son razonables\n",
        "        - No se introdujeron patrones artificiales\n",
        "        \n",
        "        Args:\n",
        "            columna: Nombre de la columna a visualizar\n",
        "        \"\"\"\n",
        "        if pd.api.types.is_numeric_dtype(self.dataframe_imputed_knn[columna]):\n",
        "            plt.figure(figsize=(16, 9))\n",
        "            \n",
        "            # Boxplot despu√©s de imputaci√≥n\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.boxplot(self.dataframe_imputed_knn[columna])\n",
        "            plt.title(f'Boxplot de {columna} (DESPU√âS de imputaci√≥n KNN)', fontweight='bold', color='green')\n",
        "            plt.ylabel('Valores')\n",
        "            \n",
        "            # Histograma despu√©s de imputaci√≥n\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.hist(self.dataframe_imputed_knn[columna], bins=20, edgecolor='k', alpha=0.7, color='lightgreen')\n",
        "            plt.title(f'Histograma de {columna} (DESPU√âS de imputaci√≥n KNN)', fontweight='bold', color='green')\n",
        "            plt.xlabel('Valores')\n",
        "            plt.ylabel('Frecuencia')\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "        else:\n",
        "            # Para variables categ√≥ricas\n",
        "            plt.figure(figsize=(16, 9))\n",
        "            self.dataframe_imputed_knn[columna].value_counts().plot(kind='bar', color='lightgreen')\n",
        "            plt.title(f'Frecuencia de {columna} (DESPU√âS de imputaci√≥n KNN)', fontweight='bold', color='green')\n",
        "            plt.xlabel(columna)\n",
        "            plt.ylabel('Frecuencia')\n",
        "            plt.xticks(rotation=45)\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8X9_IAe1GGSC"
      },
      "outputs": [],
      "source": [
        "market_store = MarketStore(MARKET_STORE_URL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "DLTzCgQuGLL6",
        "outputId": "aa386299-f6cf-4da3-951e-904cf09447ed"
      },
      "outputs": [],
      "source": [
        "market_store.get_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù Resumen del Ejercicio\n",
        "\n",
        "### ¬øQu√© aprendimos?\n",
        "\n",
        "1. **Problema de datos faltantes**: Los datasets reales casi siempre tienen valores faltantes que necesitan ser tratados\n",
        "\n",
        "2. **M√©todos de imputaci√≥n**:\n",
        "   - **Simple (media/moda)**: R√°pido pero puede distorsionar los datos\n",
        "   - **KNN**: M√°s inteligente, considera relaciones entre variables\n",
        "\n",
        "3. **Proceso de imputaci√≥n KNN**:\n",
        "   - Codificar variables categ√≥ricas ‚Üí Aplicar KNN ‚Üí Decodificar variables categ√≥ricas\n",
        "\n",
        "4. **Validaci√≥n**: Siempre comparar distribuciones antes y despu√©s para verificar la calidad de la imputaci√≥n\n",
        "\n",
        "### Pr√≥ximos pasos sugeridos:\n",
        "\n",
        "- Probar con diferentes valores de `n_neighbors` (3, 5, 7) y comparar resultados\n",
        "- Comparar visualmente las distribuciones antes y despu√©s\n",
        "- Verificar que no quedan valores nulos: `market_store.dataframe_imputed_knn.isnull().sum()`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdjzZjSKGl_6"
      },
      "outputs": [],
      "source": [
        "# market_store.get_information()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLzN7t9rIfjz"
      },
      "outputs": [],
      "source": [
        "# market_store.nullish_counting()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4GnhSzNLDfo"
      },
      "outputs": [],
      "source": [
        "# market_store.dataframe.Outlet_Size.value_counts()\n",
        "# market_store.imputar_manual()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQ0dp8ZjNs46"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVnTt3swMJL8"
      },
      "outputs": [],
      "source": [
        "# market_store.nullish_counting()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZyQ49e0RyLI"
      },
      "outputs": [],
      "source": [
        "# market_store.plot_distribution(\"Outlet_Size\")\n",
        "# market_store.plot_distribution(\"Item_Weight\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCt1bZB6VTXH",
        "outputId": "31ccd956-2095-4c75-aced-7cc3d1ec55a0"
      },
      "outputs": [],
      "source": [
        "market_store.imputacion_knn_imputer(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ho2hVReAXNHr",
        "outputId": "04d3f257-3912-45f4-85b3-72aac548d7a2"
      },
      "outputs": [],
      "source": [
        "# Ahora como podremos observar los valores por medio del KnnImputer son muchos mas uniformes\n",
        "# entregandonos una forma mas adecuada de imputar los datos\n",
        "\n",
        "market_store.plot_distribution_knn(\"Outlet_Size\")\n",
        "market_store.plot_distribution_knn(\"Item_Weight\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPMZFG4jtgif/fIsIOfcdup",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
