
# Clase: Manejo de Datos Nulos y Series Temporales en Pandas

## **Repaso de Clases Anteriores**

### üêç Ejemplo Python - Condicionales para Ciencia de Datos

**¬øPor qu√© son importantes los condicionales en ciencia de datos?**
Los condicionales nos permiten crear l√≥gica de decisi√≥n en nuestros an√°lisis, clasificar datos autom√°ticamente y aplicar diferentes tratamientos seg√∫n las caracter√≠sticas de los datos.

```python
# Clasificaci√≥n de datos seg√∫n rangos
def clasificar_edad(edad):
    """
    Funci√≥n que clasifica personas seg√∫n su edad en categor√≠as demogr√°ficas.
    
    ¬øPor qu√© usar rangos espec√≠ficos?
    - 0-17: Menor de edad (restricciones legales, comportamientos diferentes)
    - 18-65: Adulto (poblaci√≥n econ√≥micamente activa)
    - 65+: Adulto mayor (necesidades especiales, patrones de consumo diferentes)
    """
    if edad < 18:
        return "Menor de edad"
    elif 18 <= edad <= 65:
        return "Adulto"
    else:
        return "Adulto mayor"

# Aplicar a una lista de edades usando list comprehension
# ¬øPor qu√© list comprehension? Es m√°s eficiente y legible que un bucle for tradicional
edades = [15, 25, 70, 30, 12]
clasificaciones = [clasificar_edad(edad) for edad in edades]
print(clasificaciones)  # ['Menor de edad', 'Adulto', 'Adulto mayor', 'Adulto', 'Menor de edad']

# Ejemplo pr√°ctico: An√°lisis de clientes por edad
clientes = {
    'nombres': ['Ana', 'Juan', 'Mar√≠a', 'Carlos', 'Luc√≠a'],
    'edades': [15, 25, 70, 30, 12],
    'gastos': [50, 200, 150, 300, 30]
}

# Crear DataFrame y agregar clasificaci√≥n
import pandas as pd
df_clientes = pd.DataFrame(clientes)
df_clientes['categoria_edad'] = df_clientes['edades'].apply(clasificar_edad)

# An√°lisis por categor√≠a de edad
analisis_por_edad = df_clientes.groupby('categoria_edad').agg({
    'gastos': ['mean', 'count', 'sum']
}).round(2)

print("\nAn√°lisis de gastos por categor√≠a de edad:")
print(analisis_por_edad)
```

### üî¢ Ejemplo NumPy - Operaciones Vectorizadas

**¬øPor qu√© NumPy es fundamental en ciencia de datos?**
NumPy proporciona arrays multidimensionales y operaciones vectorizadas que son mucho m√°s eficientes que los bucles tradicionales de Python. Esto es crucial cuando trabajamos con grandes vol√∫menes de datos.

```python
import numpy as np

# Crear arrays y operaciones vectorizadas
# Los arrays de NumPy permiten operaciones element-wise (elemento por elemento)
# ¬øPor qu√© element-wise? Permite aplicar la misma operaci√≥n a todos los elementos simult√°neamente
temperaturas = np.array([22, 25, 18, 30, 15])
humedad = np.array([60, 70, 45, 80, 35])

print("Arrays originales:")
print(f"Temperaturas: {temperaturas}")
print(f"Humedad: {humedad}")

# Operaciones vectorizadas b√°sicas
# ¬øPor qu√© vectorizadas? Son m√°s r√°pidas que los bucles y m√°s legibles
temperaturas_fahrenheit = (temperaturas * 9/5) + 32
print(f"\nTemperaturas en Fahrenheit: {temperaturas_fahrenheit}")

# Normalizaci√≥n z-score: (x - media) / desviaci√≥n_est√°ndar
# ¬øPor qu√© normalizar? Para que los datos tengan media=0 y desviaci√≥n=1
# Esto es √∫til en machine learning para que todas las variables tengan la misma escala
temperaturas_norm = (temperaturas - np.mean(temperaturas)) / np.std(temperaturas)
print(f"\nNormalizaci√≥n Z-score:")
print(f"Temperaturas originales: {temperaturas}")
print(f"Media: {np.mean(temperaturas):.2f}")
print(f"Desviaci√≥n est√°ndar: {np.std(temperaturas):.2f}")
print(f"Temperaturas normalizadas: {temperaturas_norm}")

# Verificar que la normalizaci√≥n funcion√≥
print(f"\nVerificaci√≥n de normalizaci√≥n:")
print(f"Media de datos normalizados: {np.mean(temperaturas_norm):.6f} (deber√≠a ser ~0)")
print(f"Desv. est√°ndar de datos normalizados: {np.std(temperaturas_norm):.6f} (deber√≠a ser ~1)")

# Filtrado condicional: crea un array booleano
# ¬øPor qu√© usar arrays booleanos? Para indexaci√≥n eficiente y filtrado
dias_calidos = temperaturas > 25
print(f"\nFiltrado condicional:")
print(f"D√≠as calurosos (booleanos): {dias_calidos}")  # [False False False True False]
print(f"Temperaturas de d√≠as calurosos: {temperaturas[dias_calidos]}")  # [30]

# Operaciones m√°s complejas: √≠ndice de calor aproximado
# F√≥rmula: 0.5 * (T + 61.0 + ((T-68.0)*1.2) + (H*0.094))
# Donde T = temperatura en Fahrenheit, H = humedad relativa
indice_calor = 0.5 * (temperaturas_fahrenheit + 61.0 + 
                     ((temperaturas_fahrenheit - 68.0) * 1.2) + 
                     (humedad * 0.094))

print(f"\n√çndice de calor aproximado:")
for i, (temp, hum, indice) in enumerate(zip(temperaturas, humedad, indice_calor)):
    print(f"D√≠a {i+1}: Temp={temp}¬∞C, Hum={hum}%, √çndice={indice:.1f}¬∞F")

# Estad√≠sticas descriptivas completas
print(f"\nEstad√≠sticas descriptivas de temperaturas:")
print(f"Media: {np.mean(temperaturas):.2f}¬∞C")
print(f"Mediana: {np.median(temperaturas):.2f}¬∞C")
print(f"Desviaci√≥n est√°ndar: {np.std(temperaturas):.2f}¬∞C")
print(f"M√≠nimo: {np.min(temperaturas)}¬∞C")
print(f"M√°ximo: {np.max(temperaturas)}¬∞C")
print(f"Rango: {np.max(temperaturas) - np.min(temperaturas)}¬∞C")
```

### üìä Ejemplo Pandas - An√°lisis B√°sico

**¬øPor qu√© Pandas es la herramienta principal para an√°lisis de datos?**
Pandas proporciona estructuras de datos flexibles (Series y DataFrames) que permiten manipular, analizar y visualizar datos de manera eficiente. Es especialmente √∫til para datos tabulares y series temporales.

```python
import pandas as pd
import numpy as np

# Crear DataFrame de ventas
# Los diccionarios son √∫tiles para crear DataFrames porque las claves se convierten en nombres de columnas
ventas_data = {
    'producto': ['Laptop', 'Mouse', 'Laptop', 'Teclado', 'Mouse'],
    'cantidad': [10, 5, 15, 8, 12],
    'precio': [1000, 25, 1000, 80, 25],
    'fecha': ['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04', '2024-01-05'],
    'vendedor': ['Juan', 'Ana', 'Juan', 'Carlos', 'Ana']
}
df_ventas = pd.DataFrame(ventas_data)

# Convertir fecha a datetime para an√°lisis temporal
df_ventas['fecha'] = pd.to_datetime(df_ventas['fecha'])

print("DataFrame original:")
print(df_ventas)
print(f"\nInformaci√≥n del DataFrame:")
print(f"Dimensiones: {df_ventas.shape}")
print(f"Tipos de datos:")
print(df_ventas.dtypes)

# Calcular columna derivada: ingresos totales por venta
# ¬øPor qu√© calcular ingresos? Es una m√©trica clave para el negocio
df_ventas['ingresos'] = df_ventas['cantidad'] * df_ventas['precio']

print(f"\nDataFrame con ingresos calculados:")
print(df_ventas[['producto', 'cantidad', 'precio', 'ingresos']])

# An√°lisis por producto usando groupby
# ¬øPor qu√© groupby? Permite agrupar datos por categor√≠as y aplicar funciones de agregaci√≥n
# ¬øPor qu√© 'sum' en cantidad? Para obtener el total vendido de cada producto
# ¬øPor qu√© 'mean' en precio? Para obtener el precio promedio de cada producto
resumen_productos = df_ventas.groupby('producto').agg({
    'cantidad': 'sum',        # Suma total de cantidades por producto
    'precio': 'mean',         # Precio promedio por producto
    'ingresos': 'sum',        # Ingresos totales por producto
    'fecha': 'count'          # N√∫mero de ventas por producto
}).round(2)

resumen_productos.columns = ['Total_Unidades', 'Precio_Promedio', 'Ingresos_Totales', 'Num_Ventas']
print(f"\nResumen por producto:")
print(resumen_productos)

# An√°lisis por vendedor
resumen_vendedores = df_ventas.groupby('vendedor').agg({
    'ingresos': ['sum', 'mean', 'count']
}).round(2)

resumen_vendedores.columns = ['Ingresos_Totales', 'Ingresos_Promedio', 'Num_Ventas']
print(f"\nResumen por vendedor:")
print(resumen_vendedores)

# An√°lisis temporal: ventas por d√≠a
ventas_por_dia = df_ventas.groupby('fecha').agg({
    'ingresos': 'sum',
    'cantidad': 'sum'
}).round(2)

print(f"\nVentas por d√≠a:")
print(ventas_por_dia)

# Estad√≠sticas descriptivas completas
print(f"\nEstad√≠sticas descriptivas de ingresos:")
print(df_ventas['ingresos'].describe())

# Identificar el producto m√°s vendido y el m√°s rentable
producto_mas_vendido = df_ventas.groupby('producto')['cantidad'].sum().idxmax()
producto_mas_rentable = df_ventas.groupby('producto')['ingresos'].sum().idxmax()

print(f"\nAn√°lisis de productos:")
print(f"Producto m√°s vendido (por unidades): {producto_mas_vendido}")
print(f"Producto m√°s rentable (por ingresos): {producto_mas_rentable}")

# Calcular margen de beneficio (asumiendo costo del 60% del precio)
df_ventas['costo'] = df_ventas['precio'] * 0.6
df_ventas['beneficio'] = df_ventas['ingresos'] - (df_ventas['cantidad'] * df_ventas['costo'])
df_ventas['margen_beneficio'] = (df_ventas['beneficio'] / df_ventas['ingresos']) * 100

print(f"\nAn√°lisis de rentabilidad:")
print(df_ventas[['producto', 'ingresos', 'beneficio', 'margen_beneficio']].round(2))
```

---

## **Creaci√≥n de Series y DataFrames**

### 1.1 Creaci√≥n de Series
```python
import pandas as pd

# Desde una lista
serie_lista = pd.Series([1, 2, 3, 4, 5])
print(serie_lista)

# Desde un diccionario
serie_dict = pd.Series({'A': 10, 'B': 20, 'C': 30})
print(serie_dict)

# Con √≠ndice personalizado
serie_custom = pd.Series([100, 200, 300], index=['enero', 'febrero', 'marzo'])
print(serie_custom)
```

### 1.2 Creaci√≥n de DataFrames
```python
# Desde diccionario
data_dict = {
    'nombre': ['Ana', 'Juan', 'Mar√≠a'],
    'edad': [25, 30, 28],
    'ciudad': ['Madrid', 'Barcelona', 'Valencia']
}
df_dict = pd.DataFrame(data_dict)
print(df_dict)

# Desde lista de listas
data_lista = [
    ['Ana', 25, 'Madrid'],
    ['Juan', 30, 'Barcelona'],
    ['Mar√≠a', 28, 'Valencia']
]
df_lista = pd.DataFrame(data_lista, columns=['nombre', 'edad', 'ciudad'])
print(df_lista)
```

---

## **Operaciones B√°sicas en DataFrames**

### 2.1 Selecci√≥n de Datos

**Selecci√≥n de Columnas:**
```python
# Una columna
columna_simple = df['nombre_columna']

# M√∫ltiples columnas
columnas_multiple = df[['columna1', 'columna2', 'columna3']]
```

**Selecci√≥n de Filas:**
```python
# Por etiqueta (loc)
fila_etiqueta = df.loc['indice_etiqueta']

# Por posici√≥n (iloc)
fila_posicion = df.iloc[0]  # Primera fila
filas_rango = df.iloc[0:3]  # Filas 0, 1, 2
```

### 2.2 Filtrado de Datos

**Filtrado Simple:**
```python
# Condici√≥n √∫nica
filtro_simple = df[df['precio'] > 100]

# M√∫ltiples condiciones
filtro_multiple = df[(df['precio'] > 100) & (df['categoria'] == 'Electr√≥nicos')]
```

**Filtrado con Operadores L√≥gicos:**
```python
# AND (&)
filtro_and = df[(df['edad'] > 25) & (df['edad'] < 50)]

# OR (|)
filtro_or = df[(df['ciudad'] == 'Madrid') | (df['ciudad'] == 'Barcelona')]

# NOT (~)
filtro_not = df[~(df['categoria'] == 'Descartado')]
```

### 2.3 Agregaci√≥n de Datos

**Agregaci√≥n Simple:**
```python
# Estad√≠sticas b√°sicas
suma_total = df['cantidad'].sum()
promedio = df['precio'].mean()
conteo = df['producto'].count()
maximo = df['ventas'].max()
minimo = df['ventas'].min()
```

**Agregaci√≥n Agrupada:**
```python
# Agrupar por una columna
ventas_por_categoria = df.groupby('categoria')['ventas'].sum()

# Agrupar por m√∫ltiples columnas
ventas_por_cat_y_region = df.groupby(['categoria', 'region'])['ventas'].sum()

# M√∫ltiples funciones de agregaci√≥n
resumen_completo = df.groupby('categoria').agg({
    'ventas': ['sum', 'mean', 'count'],
    'precio': ['mean', 'std'],
    'cantidad': 'sum'
})
```

### 2.4 Ejemplos Pr√°cticos
```python
# Dataset de ejemplo
ventas_data = {
    'producto': ['Laptop', 'Mouse', 'Laptop', 'Teclado', 'Mouse'],
    'categoria': ['Electr√≥nicos', 'Accesorios', 'Electr√≥nicos', 'Accesorios', 'Accesorios'],
    'precio': [1200, 25, 1200, 80, 25],
    'cantidad': [5, 20, 3, 15, 30],
    'region': ['Norte', 'Sur', 'Norte', 'Este', 'Oeste']
}
df_ventas = pd.DataFrame(ventas_data)

# Ejemplo 1: Seleccionar productos electr√≥nicos
electronicos = df_ventas[df_ventas['categoria'] == 'Electr√≥nicos']

# Ejemplo 2: Calcular ventas totales por categor√≠a
ventas_categoria = df_ventas.groupby('categoria')['cantidad'].sum()

# Ejemplo 3: Productos con precio mayor a 100
productos_caros = df_ventas[df_ventas['precio'] > 100]

# Ejemplo 4: Resumen estad√≠stico por regi√≥n
resumen_region = df_ventas.groupby('region').agg({
    'precio': 'mean',
    'cantidad': 'sum',
    'producto': 'count'
}).round(2)
```

---

## **Manejo Avanzado de Datos Ausentes**

### 3.1 Identificaci√≥n de Datos Ausentes

**¬øPor qu√© es crucial identificar datos ausentes?**
Los datos ausentes pueden sesgar nuestros an√°lisis, afectar la precisi√≥n de los modelos de machine learning y llevar a conclusiones incorrectas. Por eso, el primer paso es siempre entender la magnitud y el patr√≥n de los valores faltantes.

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Crear dataset de ejemplo con valores ausentes
np.random.seed(42)
data_ejemplo = {
    'id': range(1, 101),
    'edad': np.random.normal(35, 10, 100),
    'salario': np.random.normal(50000, 15000, 100),
    'experiencia': np.random.normal(8, 5, 100),
    'departamento': np.random.choice(['IT', 'HR', 'Marketing', 'Ventas'], 100),
    'satisfaccion': np.random.uniform(1, 10, 100)
}

df = pd.DataFrame(data_ejemplo)

# Introducir valores ausentes de manera controlada para simular escenarios reales
# 10% de valores ausentes en edad (aleatorios)
df.loc[np.random.choice(df.index, size=int(len(df)*0.1), replace=False), 'edad'] = np.nan

# 15% de valores ausentes en salario (aleatorios)
df.loc[np.random.choice(df.index, size=int(len(df)*0.15), replace=False), 'salario'] = np.nan

# 5% de valores ausentes en departamento (aleatorios)
df.loc[np.random.choice(df.index, size=int(len(df)*0.05), replace=False), 'departamento'] = np.nan

print("Dataset con valores ausentes:")
print(df.head())
print(f"\nDimensiones del dataset: {df.shape}")

# Detectar valores ausentes
# isnull() devuelve True donde hay valores nulos, False donde no los hay
print(f"\nMatriz de valores nulos (primeras 10 filas):")
print(df.isnull().head(10))

# sum() cuenta los True (valores nulos) por columna
# ¬øPor qu√© sum()? Porque True=1, False=0, entonces sum() cuenta los nulos
valores_nulos_por_columna = df.isnull().sum()
print(f"\nValores nulos por columna:")
print(valores_nulos_por_columna)

# Informaci√≥n detallada para entender la magnitud del problema
# sum().sum() suma todos los valores nulos del DataFrame completo
total_nulos = df.isnull().sum().sum()
# df.size es el total de elementos en el DataFrame (filas √ó columnas)
porcentaje_nulos = (total_nulos / df.size) * 100

print(f"\nResumen de valores ausentes:")
print(f"Total de valores nulos: {total_nulos}")
print(f"Porcentaje de valores nulos: {porcentaje_nulos:.2f}%")
print(f"Total de elementos en el dataset: {df.size}")

# An√°lisis m√°s detallado
print(f"\nAn√°lisis detallado por columna:")
for columna in df.columns:
    nulos = df[columna].isnull().sum()
    porcentaje = (nulos / len(df)) * 100
    print(f"{columna}: {nulos} valores nulos ({porcentaje:.1f}%)")

# Visualizaci√≥n de valores ausentes
plt.figure(figsize=(12, 8))

# Gr√°fico 1: Conteo de valores nulos por columna
plt.subplot(2, 2, 1)
valores_nulos_por_columna.plot(kind='bar', color='red', alpha=0.7)
plt.title('Valores Nulos por Columna')
plt.ylabel('Cantidad de Valores Nulos')
plt.xticks(rotation=45)

# Gr√°fico 2: Porcentaje de valores nulos por columna
plt.subplot(2, 2, 2)
porcentajes_nulos = (valores_nulos_por_columna / len(df)) * 100
porcentajes_nulos.plot(kind='bar', color='orange', alpha=0.7)
plt.title('Porcentaje de Valores Nulos por Columna')
plt.ylabel('Porcentaje (%)')
plt.xticks(rotation=45)

# Gr√°fico 3: Matriz de valores ausentes (heatmap)
plt.subplot(2, 2, 3)
sns.heatmap(df.isnull(), cbar=True, yticklabels=False, cmap='viridis')
plt.title('Matriz de Valores Ausentes')
plt.xlabel('Columnas')

# Gr√°fico 4: Distribuci√≥n de valores nulos en el dataset
plt.subplot(2, 2, 4)
filas_con_nulos = df.isnull().sum(axis=1)
plt.hist(filas_con_nulos, bins=range(filas_con_nulos.max() + 2), alpha=0.7, color='green')
plt.title('Distribuci√≥n de Valores Nulos por Fila')
plt.xlabel('N√∫mero de Valores Nulos por Fila')
plt.ylabel('Frecuencia')

plt.tight_layout()
plt.show()

# An√°lisis de patrones de valores ausentes
print(f"\nAn√°lisis de patrones:")
print(f"Filas sin valores nulos: {(df.isnull().sum(axis=1) == 0).sum()}")
print(f"Filas con al menos un valor nulo: {(df.isnull().sum(axis=1) > 0).sum()}")

# Identificar filas con m√∫ltiples valores nulos
filas_problematicas = df[df.isnull().sum(axis=1) >= 2]
print(f"\nFilas con 2 o m√°s valores nulos: {len(filas_problematicas)}")
if len(filas_problematicas) > 0:
    print("Ejemplos de filas problem√°ticas:")
    print(filas_problematicas.head())
```

### 3.2 Eliminaci√≥n de Datos Ausentes
```python
# Eliminar filas con valores nulos
df_sin_nulos = df.dropna()  # Elimina filas con al menos un valor nulo

# Eliminar columnas con valores nulos
df_sin_columnas_nulas = df.dropna(axis=1)

# Eliminar solo si todos los valores son nulos
df_limpiado = df.dropna(how='all')  # Solo filas completamente vac√≠as

# Eliminar si hay al menos 2 valores nulos
df_parcial = df.dropna(thresh=len(df.columns)-2)
```

### 3.3 Imputaci√≥n B√°sica con Pandas

**¬øCu√°ndo usar cada t√©cnica de imputaci√≥n?**
La elecci√≥n del m√©todo de imputaci√≥n depende del tipo de datos, el contexto del problema y el patr√≥n de valores ausentes. Es crucial entender las implicaciones de cada m√©todo.

```python
# Continuamos con el dataset anterior
print("Dataset original con valores ausentes:")
print(df.head())
print(f"\nValores nulos antes de imputaci√≥n:")
print(df.isnull().sum())

# Crear copias para comparar diferentes m√©todos
df_media = df.copy()
df_mediana = df.copy()
df_constante = df.copy()
df_forward = df.copy()

# 1. Rellenar con valor constante
# ¬øCu√°ndo usar 0? Cuando los valores nulos representan "sin valor" o "no aplica"
# Ejemplo: gastos de marketing para clientes que no tienen campa√±a activa
df_constante.fillna(0, inplace=True)

# 2. Imputar con estad√≠sticas por columna
# ¬øPor qu√© media para edad? Es representativa cuando los datos est√°n normalmente distribuidos
# Ventaja: Mantiene la media de la distribuci√≥n original
# Desventaja: Puede no ser representativa si hay outliers
df_media['edad'].fillna(df_media['edad'].mean(), inplace=True)

# ¬øPor qu√© mediana para salario? Es robusta a outliers (valores extremos)
# Ventaja: No se ve afectada por valores extremos
# Desventaja: Puede no reflejar la distribuci√≥n real si hay muchos outliers
df_mediana['salario'].fillna(df_mediana['salario'].median(), inplace=True)

# ¬øPor qu√© moda para categor√≠as? Es el valor m√°s frecuente, l√≥gico para datos categ√≥ricos
# Ventaja: Mantiene la categor√≠a m√°s com√∫n
# Desventaja: Puede crear sesgo si una categor√≠a es muy dominante
df_media['departamento'].fillna(df_media['departamento'].mode()[0], inplace=True)

# 3. Forward fill y backward fill para series temporales
# ¬øCu√°ndo usar ffill? Cuando el valor anterior es una buena estimaci√≥n (ej: precio de ayer)
# Ventaja: Mantiene la continuidad temporal
# Desventaja: Puede propagar errores
df_forward['edad'].fillna(method='ffill', inplace=True)

# ¬øCu√°ndo usar bfill? Cuando el valor siguiente es m√°s relevante
# Ventaja: √ötil cuando los valores futuros son m√°s informativos
# Desventaja: Puede no estar disponible para el √∫ltimo valor
df_forward['salario'].fillna(method='bfill', inplace=True)

# Comparar resultados de diferentes m√©todos
print(f"\nComparaci√≥n de m√©todos de imputaci√≥n:")

# Estad√≠sticas de edad antes y despu√©s
print(f"\nEstad√≠sticas de EDAD:")
print(f"Original (sin nulos): Media={df['edad'].mean():.2f}, Mediana={df['edad'].median():.2f}")
print(f"Con media: Media={df_media['edad'].mean():.2f}, Mediana={df_media['edad'].median():.2f}")
print(f"Con forward fill: Media={df_forward['edad'].mean():.2f}, Mediana={df_forward['edad'].median():.2f}")

# Estad√≠sticas de salario antes y despu√©s
print(f"\nEstad√≠sticas de SALARIO:")
print(f"Original (sin nulos): Media={df['salario'].mean():.2f}, Mediana={df['salario'].median():.2f}")
print(f"Con mediana: Media={df_mediana['salario'].mean():.2f}, Mediana={df_mediana['salario'].median():.2f}")
print(f"Con backward fill: Media={df_forward['salario'].mean():.2f}, Mediana={df_forward['salario'].median():.2f}")

# Visualizar el impacto de diferentes m√©todos
plt.figure(figsize=(15, 10))

# Gr√°fico 1: Distribuci√≥n de edad
plt.subplot(2, 3, 1)
plt.hist(df['edad'].dropna(), bins=20, alpha=0.7, label='Original', color='blue')
plt.hist(df_media['edad'], bins=20, alpha=0.7, label='Con media', color='red')
plt.title('Distribuci√≥n de Edad')
plt.legend()

# Gr√°fico 2: Distribuci√≥n de salario
plt.subplot(2, 3, 2)
plt.hist(df['salario'].dropna(), bins=20, alpha=0.7, label='Original', color='blue')
plt.hist(df_mediana['salario'], bins=20, alpha=0.7, label='Con mediana', color='green')
plt.title('Distribuci√≥n de Salario')
plt.legend()

# Gr√°fico 3: Boxplot comparativo de edad
plt.subplot(2, 3, 3)
datos_edad = [df['edad'].dropna(), df_media['edad'], df_forward['edad']]
plt.boxplot(datos_edad, labels=['Original', 'Media', 'Forward Fill'])
plt.title('Boxplot de Edad por M√©todo')

# Gr√°fico 4: Boxplot comparativo de salario
plt.subplot(2, 3, 4)
datos_salario = [df['salario'].dropna(), df_mediana['salario'], df_forward['salario']]
plt.boxplot(datos_salario, labels=['Original', 'Mediana', 'Backward Fill'])
plt.title('Boxplot de Salario por M√©todo')

# Gr√°fico 5: Distribuci√≥n de departamentos
plt.subplot(2, 3, 5)
df['departamento'].value_counts().plot(kind='bar', alpha=0.7, label='Original', color='blue')
df_media['departamento'].value_counts().plot(kind='bar', alpha=0.7, label='Con moda', color='orange')
plt.title('Distribuci√≥n de Departamentos')
plt.legend()
plt.xticks(rotation=45)

# Gr√°fico 6: Comparaci√≥n de estad√≠sticas
plt.subplot(2, 3, 6)
metodos = ['Original', 'Media', 'Mediana', 'Forward Fill']
medias_edad = [df['edad'].mean(), df_media['edad'].mean(), 
               df_mediana['edad'].mean(), df_forward['edad'].mean()]
plt.bar(metodos, medias_edad, color=['blue', 'red', 'green', 'purple'], alpha=0.7)
plt.title('Media de Edad por M√©todo')
plt.ylabel('Edad Promedio')
plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

# An√°lisis de correlaciones antes y despu√©s de la imputaci√≥n
print(f"\nAn√°lisis de correlaciones:")
print(f"Correlaci√≥n original (edad vs salario): {df['edad'].corr(df['salario']):.3f}")
print(f"Correlaci√≥n con imputaci√≥n por media: {df_media['edad'].corr(df_media['salario']):.3f}")
print(f"Correlaci√≥n con imputaci√≥n por mediana: {df_mediana['edad'].corr(df_mediana['salario']):.3f}")

# Evaluaci√≥n de la calidad de la imputaci√≥n
def evaluar_imputacion(df_original, df_imputado, columna):
    """
    Eval√∫a la calidad de la imputaci√≥n comparando estad√≠sticas
    """
    original_sin_nulos = df_original[columna].dropna()
    imputado = df_imputado[columna]
    
    # Calcular diferencias en estad√≠sticas
    diff_media = abs(original_sin_nulos.mean() - imputado.mean())
    diff_mediana = abs(original_sin_nulos.median() - imputado.median())
    diff_std = abs(original_sin_nulos.std() - imputado.std())
    
    print(f"\nEvaluaci√≥n para {columna}:")
    print(f"Diferencia en media: {diff_media:.2f}")
    print(f"Diferencia en mediana: {diff_mediana:.2f}")
    print(f"Diferencia en desviaci√≥n est√°ndar: {diff_std:.2f}")

evaluar_imputacion(df, df_media, 'edad')
evaluar_imputacion(df, df_mediana, 'salario')
```

### 3.4 Imputaci√≥n Avanzada con Scikit-Learn
```python
from sklearn.impute import SimpleImputer, KNNImputer

# SimpleImputer con diferentes estrategias
# ¬øPor qu√© usar SimpleImputer? Es m√°s robusto y permite aplicar la misma estrategia a m√∫ltiples columnas
imputer_media = SimpleImputer(strategy='mean')
imputer_mediana = SimpleImputer(strategy='median')
imputer_moda = SimpleImputer(strategy='most_frequent')
imputer_constante = SimpleImputer(strategy='constant', fill_value=0)

# Aplicar a columnas num√©ricas
# ¬øPor qu√© select_dtypes? Para aplicar solo a columnas num√©ricas, no a texto
columnas_numericas = df.select_dtypes(include=[np.number]).columns
df[columnas_numericas] = imputer_media.fit_transform(df[columnas_numericas])

# KNN Imputer (m√°s sofisticado)
# ¬øPor qu√© KNN? Usa los datos m√°s similares para imputar, preservando relaciones entre variables
# ¬øPor qu√© n_neighbors=5? Balance entre precisi√≥n y velocidad (m√°s vecinos = m√°s preciso pero m√°s lento)
knn_imputer = KNNImputer(n_neighbors=5)
df_imputado_knn = pd.DataFrame(
    knn_imputer.fit_transform(df),
    columns=df.columns,
    index=df.index
)
```

### 3.5 Ejemplo Pr√°ctico Completo
```python
import pandas as pd
import numpy as np
from sklearn.impute import SimpleImputer

# Dataset con valores ausentes
data_ejemplo = {
    'id': [1, 2, 3, 4, 5],
    'nombre': ['Ana', 'Juan', None, 'Mar√≠a', 'Carlos'],
    'edad': [25, None, 30, 28, None],
    'salario': [50000, 60000, None, 55000, 70000],
    'departamento': ['IT', 'HR', 'IT', None, 'IT']
}
df_ejemplo = pd.DataFrame(data_ejemplo)

print("Dataset original:")
print(df_ejemplo)
print("\nValores nulos por columna:")
print(df_ejemplo.isnull().sum())

# Estrategia de imputaci√≥n
# 1. Texto: moda
# 2. N√∫meros: media
# 3. Categor√≠as: moda

# Imputar texto
df_ejemplo['nombre'].fillna(df_ejemplo['nombre'].mode()[0], inplace=True)

# Imputar n√∫meros
df_ejemplo['edad'].fillna(df_ejemplo['edad'].mean(), inplace=True)
df_ejemplo['salario'].fillna(df_ejemplo['salario'].mean(), inplace=True)

# Imputar categor√≠as
df_ejemplo['departamento'].fillna(df_ejemplo['departamento'].mode()[0], inplace=True)

print("\nDataset despu√©s de imputaci√≥n:")
print(df_ejemplo)
```

---

## **Manipulaci√≥n de Strings en Pandas**

### 4.1 Operaciones B√°sicas de Strings
```python
# Acceder a m√©todos de string
# ¬øPor qu√© .str? Permite aplicar m√©todos de string a cada elemento de la columna
df['nombre'].str.upper()  # Convertir a may√∫sculas - √∫til para estandarizar
df['email'].str.lower()   # Convertir a min√∫sculas - emails no distinguen may√∫sculas/min√∫sculas
df['texto'].str.strip()   # Eliminar espacios en blanco - limpia datos ingresados manualmente

# Longitud de strings
# ¬øPara qu√© sirve? Detectar valores an√≥malos (nombres muy cortos/largos)
df['nombre'].str.len()    # Longitud de cada string

# Concatenaci√≥n
# ¬øPor qu√© sep=' '? Para separar nombre y apellido con un espacio
df['nombre_completo'] = df['nombre'].str.cat(df['apellido'], sep=' ')
```

### 4.2 B√∫squeda y Filtrado
```python
# Contiene un patr√≥n
# ¬øPor qu√© case=False? Para hacer b√∫squeda insensible a may√∫sculas/min√∫sculas
df[df['producto'].str.contains('laptop', case=False)]

# Comienza con
# ¬øPara qu√© sirve? Filtrar emails administrativos, c√≥digos que empiecen igual
df[df['email'].str.startswith('admin')]

# Termina con
# ¬øPara qu√© sirve? Filtrar por extensiones de archivo, dominios de email
df[df['archivo'].str.endswith('.csv')]

# Coincidencia exacta con regex
# ¬øPor qu√© ^ y $? ^ = inicio de string, $ = fin de string, para coincidencia exacta
df[df['categoria'].str.match('^Electr√≥nicos$')]
```

### 4.3 Extracci√≥n y Reemplazo
```python
# Extraer parte del string usando regex
# ¬øQu√© hace r'\+(\d+)'? \+ = s√≠mbolo + literal, (\d+) = uno o m√°s d√≠gitos (capturados)
df['codigo_pais'] = df['telefono'].str.extract(r'\+(\d+)')

# ¬øQu√© hace r'@(.+)'? @ = s√≠mbolo @ literal, (.+) = cualquier car√°cter despu√©s del @
df['dominio'] = df['email'].str.extract(r'@(.+)')

# Reemplazar patrones
# ¬øQu√© hace r'[^\d]'? [^\d] = cualquier car√°cter que NO sea d√≠gito
df['telefono_limpio'] = df['telefono'].str.replace(r'[^\d]', '', regex=True)

# ¬øPor qu√© encadenar replace? Para eliminar m√∫ltiples caracteres en secuencia
df['precio_limpio'] = df['precio'].str.replace('$', '').str.replace(',', '')

# Split y join
# ¬øPor qu√© split()? Para separar texto en palabras individuales
df['palabras'] = df['descripcion'].str.split()
# ¬øPor qu√© .str[0]? Para obtener la primera palabra despu√©s del split
df['primera_palabra'] = df['descripcion'].str.split().str[0]
```

### 4.4 Validaci√≥n y Limpieza
```python
# Validar formato de email
# ¬øPor qu√© usar regex para validar? Para verificar que el formato sea correcto
def es_email_valido(email):
    import re
    # Patr√≥n regex: usuario@dominio.extension
    # ^ = inicio, [a-zA-Z0-9._%+-]+ = caracteres permitidos en usuario
    # @ = s√≠mbolo @, [a-zA-Z0-9.-]+ = caracteres permitidos en dominio
    # \. = punto literal, [a-zA-Z]{2,} = extensi√≥n de 2+ letras, $ = fin
    patron = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    return bool(re.match(patron, str(email)))

df['email_valido'] = df['email'].apply(es_email_valido)

# Limpiar nombres - encadenamiento de m√©todos
# ¬øPor qu√© encadenar? Para aplicar m√∫ltiples transformaciones en una l√≠nea
df['nombre_limpio'] = (df['nombre']
                      .str.strip()                    # Eliminar espacios
                      .str.title()                    # Capitalizar palabras
                      .str.replace(r'\s+', ' ', regex=True))  # M√∫ltiples espacios ‚Üí uno
```

### 4.5 Ejemplo Pr√°ctico de Limpieza de Datos
```python
# Dataset con datos textuales sucios
datos_sucios = {
    'nombre': ['  juan p√©rez  ', 'MAR√çA GARC√çA', 'carlos lopez'],
    'email': ['juan@email.com', 'maria@email.com', 'carlos@email.com'],
    'telefono': ['+34 123-456-789', '+34 987-654-321', '+34 555-123-456'],
    'precio': ['$1,234.56', '$2,345.67', '$3,456.78']
}
df_sucio = pd.DataFrame(datos_sucios)

print("Datos originales:")
print(df_sucio)

# Limpieza completa
df_limpio = df_sucio.copy()

# Limpiar nombres
df_limpio['nombre'] = (df_limpio['nombre']
                      .str.strip()
                      .str.title()
                      .str.replace(r'\s+', ' ', regex=True))

# Limpiar tel√©fonos
df_limpio['telefono_limpio'] = df_limpio['telefono'].str.replace(r'[^\d]', '', regex=True)

# Limpiar precios
df_limpio['precio_numerico'] = (df_limpio['precio']
                               .str.replace('$', '')
                               .str.replace(',', '')
                               .astype(float))

# Extraer dominio de email
df_limpio['dominio_email'] = df_limpio['email'].str.extract(r'@(.+)')

print("\nDatos limpios:")
print(df_limpio)
```

---

## **Objetivos de Aprendizaje**
1. Identificar y clasificar tipos de datos nulos
2. Aplicar t√©cnicas b√°sicas y avanzadas de imputaci√≥n
3. Manipular series temporales con Pandas
4. Implementar estrategias para manejar valores faltantes en series de tiempo

### [DIAPOSITIVAS](https://docs.google.com/presentation/d/1BDjUNhpNr1TD8qRBV6XkHkUUbZhho8Ks5wzouYfjLRY/edit?slide=id.g2f3430c3b8e_0_258#slide=id.g2f3430c3b8e_0_258)


## **Bloque 1: Manejo de Datos Nulos**

### 1.1 Teor√≠a Fundamental
**¬øQu√© son los datos nulos?**  
Valores ausentes representados como `NaN` (Not a Number) o `None` en Python. Surgen por:
- Errores en captura de datos
- Campos opcionales no completados
- Fallas en sensores/dispositivos [1][3]

**Impacto en el an√°lisis:**
- Reducci√≥n de potencia estad√≠stica
- Sesgos en modelos predictivos
- Errores en c√°lculos matem√°ticos

### 1.2 T√©cnicas de Imputaci√≥n

**B√°sicas:**
```python
# Eliminaci√≥n
df.dropna(axis=0)  # Filas
df.dropna(axis=1)  # Columnas [1]

# Relleno con constante
df.fillna(0)

# Medidas de tendencia central
df.fillna(df.mean())  # Media
df.fillna(df.median())  # Mediana [4]
```

**Avanzadas (usando scikit-learn):**
```python
from sklearn.impute import KNNImputer

imputer = KNNImputer(n_neighbors=3)
df_imputado = imputer.fit_transform(df) [2][4]
```

**Interpolaci√≥n temporal:**
```python
df['serie'].interpolate(method='time') [7]
```

### 1.3 Ejercicio Pr√°ctico
```python
# Dataset con valores faltantes
data = {'A': [1, 2, None, 4], 'B': [None, 2, 3, 4]}
df = pd.DataFrame(data)

# Tarea: Implementar 3 t√©cnicas diferentes
# y comparar resultados
```

---

## **Bloque 2: Series Temporales en Pandas**

### 2.1 Fundamentos
**Caracter√≠sticas clave:**
- √çndice datetime como eje principal
- Frecuencia consistente (diaria, mensual, etc.)
- Operaciones especializadas (resampling, ventanas m√≥viles)

**Creaci√≥n b√°sica:**
```python
# Conversi√≥n a datetime
df['fecha'] = pd.to_datetime(df['fecha'], format='%d-%m-%Y')
df = df.set_index('fecha') [5][6]
```

### 2.2 T√©cnicas Avanzadas

**Resampling:**
```python
# Mensual a diario con forward fill
daily_df = df.resample('D').asfreq().ffill() [7]

# Promedio m√≥vil 7 d√≠as
df.rolling(window='7D').mean()
```

**Manejo de faltantes temporales:**
```python
# Interpolaci√≥n cuadr√°tica
df.interpolate(method='quadratic')

# Llenado con √∫ltimo valor v√°lido
df.ffill() [1][5]
```

### 2.3 Ejercicio Integrador
```python
# Dataset de ventas con huecos temporales
ventas = pd.Series([100, None, 150, None, 200], 
                  index=pd.date_range('2024-01-01', periods=5))

# Tarea: 
# 1. Completar valores faltantes con interpolaci√≥n
# 2. Calcular promedio m√≥vil de 2 d√≠as
# 3. Convertir a frecuencia horaria con forward fill
```

---

## **Actividades Sugeridas**
1. **An√°lisis comparativo:** Probar diferentes m√©todos de imputaci√≥n en un dataset real y evaluar impacto en estad√≠sticas descriptivas
2. **Competici√≥n de imputaci√≥n:** En grupos, desarrollar estrategias para dataset con 30% valores faltantes y comparar resultados
3. **Proyecto de series temporales:** Analizar datos clim√°ticos con patrones estacionales y valores faltantes

---

# Graficos




###  Tabla: Gr√°ficos recomendados para an√°lisis exploratorio

| Gr√°fico         | Uso principal                                                       | ¬øCu√°ndo es excelente?                                                            | Librer√≠a en Python      |
| --------------- | ------------------------------------------------------------------- | -------------------------------------------------------------------------------- | ----------------------- |
| **Boxplot**     | Visualizar distribuci√≥n, mediana, rangos y outliers                 | Para comparar la dispersi√≥n de una variable num√©rica entre categor√≠as            | `seaborn`, `matplotlib` |
| **Scatterplot** | Mostrar la relaci√≥n entre dos variables num√©ricas                   | Para detectar patrones, tendencias, relaciones lineales o no lineales y outliers | `seaborn`, `matplotlib` |
| **Lineplot**    | Mostrar la evoluci√≥n de una variable num√©rica a lo largo del tiempo | Para observar tendencias temporales o secuenciales                               | `seaborn`, `matplotlib` |
| **Barplot**     | Comparar valores agregados (suma, media, etc.) entre categor√≠as     | Ideal para comparar cantidades entre grupos o categor√≠as                         | `seaborn`, `matplotlib` |
| **Histograma**  | Visualizar la distribuci√≥n de frecuencia de una variable num√©rica   | Para ver c√≥mo se distribuyen los valores, si hay sesgo, bimodalidad, etc.        | `matplotlib`, `seaborn` |

---

### ‚úÖ Explicaci√≥n r√°pida:

#### 1. **Boxplot**

* **√ötil para:** ver la dispersi√≥n, detectar valores extremos.
* **Ideal para:** comparar por categor√≠a (ej.: ventas por tipo de producto).

#### 2. **Scatterplot**

* **√ötil para:** descubrir relaciones entre dos variables num√©ricas.
* **Ideal para:** detectar correlaciones, cl√∫steres o anomal√≠as.

#### 3. **Lineplot**

* **√ötil para:** an√°lisis de series de tiempo o progresi√≥n.
* **Ideal para:** ver tendencias de ventas, precios, tr√°fico, etc.

#### 4. **Barplot**

* **√ötil para:** comparar cantidades resumidas.
* **Ideal para:** mostrar promedios o totales por grupo.

#### 5. **Histograma**

* **√ötil para:** ver la distribuci√≥n de valores.
* **Ideal para:** analizar simetr√≠a, sesgo o agrupaciones naturales.

---

## **4.4 Matplotlib - Visualizaci√≥n de Datos**

### ¬øQu√© es Matplotlib?

**Matplotlib** es una de las bibliotecas m√°s populares en Python para la creaci√≥n de gr√°ficos y visualizaciones de datos. Fundada en 2003 por John D. Hunter, proporciona herramientas robustas para generar gr√°ficos bidimensionales de alta calidad. Es fundamental para cualquiera que trabaje con datos en Python, siendo la base sobre la cual se han construido otras bibliotecas como Seaborn y Plotly.

### ¬øPor qu√© Matplotlib?

Matplotlib se destaca por su **simplicidad y flexibilidad**. Aunque existen otras bibliotecas para la visualizaci√≥n de datos, Matplotlib sigue siendo la m√°s utilizada gracias a su capacidad para generar gr√°ficos altamente personalizables. Adem√°s, al ser de c√≥digo abierto, es accesible y ampliamente utilizada por la comunidad cient√≠fica y de desarrollo.

### Interfaces Principales de Matplotlib

Matplotlib ofrece dos interfaces principales:

1. **Interfaz orientada a objetos**: Es la m√°s flexible y poderosa, permitiendo un control detallado sobre los gr√°ficos. Trata a los gr√°ficos como objetos reutilizables, lo que es ideal para crear gr√°ficos complejos o manejar m√∫ltiples gr√°ficos simult√°neamente.

2. **Interfaz orientada a estados (pyplot)**: Similar a MATLAB, esta interfaz es m√°s simple y directa, ideal para gr√°ficos r√°pidos. Sin embargo, para gr√°ficos m√°s complejos, la interfaz orientada a objetos es preferida por su mayor control y flexibilidad.

### Configuraci√≥n Inicial y Uso B√°sico

```python
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

# Configuraci√≥n de estilo para gr√°ficos m√°s atractivos
plt.style.use('seaborn-v0_8')  # Estilo moderno y atractivo
plt.rcParams['figure.figsize'] = (10, 6)  # Tama√±o por defecto de las figuras
plt.rcParams['font.size'] = 12  # Tama√±o de fuente por defecto

# Crear datos de ejemplo
np.random.seed(42)  # Para reproducibilidad
x = np.linspace(0, 10, 100)
y = np.sin(x) + np.random.normal(0, 0.1, 100)

# Gr√°fico b√°sico usando la interfaz orientada a objetos
fig, ax = plt.subplots(figsize=(10, 6))
ax.plot(x, y, 'b-', linewidth=2, label='Datos con ruido')
ax.plot(x, np.sin(x), 'r--', linewidth=2, label='Funci√≥n seno original')
ax.set_xlabel('Eje X', fontsize=14)
ax.set_ylabel('Eje Y', fontsize=14)
ax.set_title('Gr√°fico de L√≠neas con Matplotlib', fontsize=16, fontweight='bold')
ax.legend(fontsize=12)
ax.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

### Tipos de Gr√°ficos Comunes

#### 1. **Gr√°fico de L√≠neas (Line Plot)**

```python
# Datos de ventas mensuales
meses = ['Ene', 'Feb', 'Mar', 'Abr', 'May', 'Jun']
ventas = [120, 150, 180, 200, 220, 250]
gastos = [100, 120, 140, 160, 180, 200]

fig, ax = plt.subplots(figsize=(10, 6))
ax.plot(meses, ventas, 'o-', linewidth=2, markersize=8, label='Ventas', color='blue')
ax.plot(meses, gastos, 's-', linewidth=2, markersize=8, label='Gastos', color='red')
ax.set_xlabel('Mes', fontsize=14)
ax.set_ylabel('Monto ($)', fontsize=14)
ax.set_title('Evoluci√≥n de Ventas vs Gastos', fontsize=16, fontweight='bold')
ax.legend(fontsize=12)
ax.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

#### 2. **Gr√°fico de Barras (Bar Plot)**

```python
# Datos de productos m√°s vendidos
productos = ['Laptop', 'Mouse', 'Teclado', 'Monitor', 'Auriculares']
ventas = [45, 120, 80, 30, 95]

fig, ax = plt.subplots(figsize=(10, 6))
bars = ax.bar(productos, ventas, color=['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#592E83'])
ax.set_xlabel('Producto', fontsize=14)
ax.set_ylabel('Unidades Vendidas', fontsize=14)
ax.set_title('Ventas por Producto', fontsize=16, fontweight='bold')

# Agregar valores sobre las barras
for bar, venta in zip(bars, ventas):
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height + 1,
            f'{venta}', ha='center', va='bottom', fontsize=12, fontweight='bold')

plt.tight_layout()
plt.show()
```

#### 3. **Gr√°fico de Dispersi√≥n (Scatter Plot)**

```python
# Datos de relaci√≥n entre precio y ventas
np.random.seed(42)
precios = np.random.uniform(50, 500, 50)
ventas = 1000 - 1.5 * precios + np.random.normal(0, 50, 50)

fig, ax = plt.subplots(figsize=(10, 6))
scatter = ax.scatter(precios, ventas, c=ventas, cmap='viridis', s=100, alpha=0.7)
ax.set_xlabel('Precio ($)', fontsize=14)
ax.set_ylabel('Ventas (unidades)', fontsize=14)
ax.set_title('Relaci√≥n Precio vs Ventas', fontsize=16, fontweight='bold')

# Agregar l√≠nea de tendencia
z = np.polyfit(precios, ventas, 1)
p = np.poly1d(z)
ax.plot(precios, p(precios), "r--", alpha=0.8, linewidth=2, label='Tendencia')

# Agregar barra de color
cbar = plt.colorbar(scatter)
cbar.set_label('Nivel de Ventas', fontsize=12)

ax.legend(fontsize=12)
plt.tight_layout()
plt.show()
```

#### 4. **Histograma**

```python
# Datos de edades de clientes
np.random.seed(42)
edades = np.random.normal(35, 12, 1000)  # Media=35, Desv=12, 1000 clientes

fig, ax = plt.subplots(figsize=(10, 6))
n, bins, patches = ax.hist(edades, bins=30, alpha=0.7, color='skyblue', edgecolor='black')

# Agregar l√≠nea de densidad normal
from scipy.stats import norm
xmin, xmax = ax.get_xlim()
x = np.linspace(xmin, xmax, 100)
p = norm.pdf(x, np.mean(edades), np.std(edades))
ax.plot(x, p * len(edades) * (bins[1] - bins[0]), 'r-', linewidth=2, label='Distribuci√≥n Normal')

ax.set_xlabel('Edad', fontsize=14)
ax.set_ylabel('Frecuencia', fontsize=14)
ax.set_title('Distribuci√≥n de Edades de Clientes', fontsize=16, fontweight='bold')
ax.legend(fontsize=12)
ax.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

#### 5. **Boxplot**

```python
# Datos de salarios por departamento
np.random.seed(42)
it_salarios = np.random.normal(65000, 15000, 100)
hr_salarios = np.random.normal(55000, 12000, 100)
marketing_salarios = np.random.normal(60000, 18000, 100)

fig, ax = plt.subplots(figsize=(10, 6))
data = [it_salarios, hr_salarios, marketing_salarios]
labels = ['IT', 'Recursos Humanos', 'Marketing']

box_plot = ax.boxplot(data, labels=labels, patch_artist=True)

# Colorear las cajas
colors = ['lightblue', 'lightgreen', 'lightcoral']
for patch, color in zip(box_plot['boxes'], colors):
    patch.set_facecolor(color)

ax.set_ylabel('Salario Anual ($)', fontsize=14)
ax.set_title('Distribuci√≥n de Salarios por Departamento', fontsize=16, fontweight='bold')
ax.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

### Subplots y M√∫ltiples Gr√°ficos

```python
# Crear m√∫ltiples gr√°ficos en una sola figura
fig, axes = plt.subplots(2, 2, figsize=(15, 10))
fig.suptitle('Dashboard de An√°lisis de Datos', fontsize=16, fontweight='bold')

# Gr√°fico 1: L√≠nea temporal
axes[0, 0].plot(meses, ventas, 'o-', color='blue')
axes[0, 0].set_title('Ventas Mensuales')
axes[0, 0].set_ylabel('Ventas ($)')
axes[0, 0].grid(True, alpha=0.3)

# Gr√°fico 2: Barras
axes[0, 1].bar(productos, ventas, color='green', alpha=0.7)
axes[0, 1].set_title('Ventas por Producto')
axes[0, 1].set_ylabel('Unidades')

# Gr√°fico 3: Dispersi√≥n
axes[1, 0].scatter(precios, ventas, alpha=0.6, color='red')
axes[1, 0].set_title('Precio vs Ventas')
axes[1, 0].set_xlabel('Precio ($)')
axes[1, 0].set_ylabel('Ventas')

# Gr√°fico 4: Histograma
axes[1, 1].hist(edades, bins=20, alpha=0.7, color='purple')
axes[1, 1].set_title('Distribuci√≥n de Edades')
axes[1, 1].set_xlabel('Edad')
axes[1, 1].set_ylabel('Frecuencia')

plt.tight_layout()
plt.show()
```

### Personalizaci√≥n Avanzada

```python
# Gr√°fico con personalizaci√≥n completa
fig, ax = plt.subplots(figsize=(12, 8))

# Crear datos
x = np.linspace(0, 2*np.pi, 100)
y1 = np.sin(x)
y2 = np.cos(x)

# Gr√°fico principal
line1 = ax.plot(x, y1, 'b-', linewidth=3, label='Seno', alpha=0.8)
line2 = ax.plot(x, y2, 'r-', linewidth=3, label='Coseno', alpha=0.8)

# Personalizar ejes
ax.set_xlim(0, 2*np.pi)
ax.set_ylim(-1.2, 1.2)
ax.set_xlabel('√Ångulo (radianes)', fontsize=14, fontweight='bold')
ax.set_ylabel('Valor', fontsize=14, fontweight='bold')
ax.set_title('Funciones Trigonom√©tricas', fontsize=16, fontweight='bold', pad=20)

# Personalizar cuadr√≠cula
ax.grid(True, linestyle='--', alpha=0.7, color='gray')
ax.set_axisbelow(True)  # Poner la cuadr√≠cula detr√°s de los datos

# Personalizar leyenda
ax.legend(loc='upper right', fontsize=12, framealpha=0.9, shadow=True)

# Agregar anotaciones
ax.annotate('M√°ximo del Seno', xy=(np.pi/2, 1), xytext=(np.pi/2 + 0.5, 1.1),
            arrowprops=dict(arrowstyle='->', color='blue', lw=2),
            fontsize=12, color='blue')

ax.annotate('M√°ximo del Coseno', xy=(0, 1), xytext=(-0.5, 1.1),
            arrowprops=dict(arrowstyle='->', color='red', lw=2),
            fontsize=12, color='red')

# Personalizar el fondo
ax.set_facecolor('#f8f9fa')
fig.patch.set_facecolor('white')

plt.tight_layout()
plt.show()
```

### Guardar Gr√°ficos

```python
# Crear un gr√°fico y guardarlo en diferentes formatos
fig, ax = plt.subplots(figsize=(10, 6))
ax.plot(x, y1, 'b-', linewidth=2, label='Seno')
ax.plot(x, y2, 'r-', linewidth=2, label='Coseno')
ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_title('Funciones Trigonom√©tricas')
ax.legend()
ax.grid(True, alpha=0.3)

# Guardar en diferentes formatos
plt.savefig('grafico.png', dpi=300, bbox_inches='tight')  # PNG de alta calidad
plt.savefig('grafico.pdf', bbox_inches='tight')  # PDF vectorial
plt.savefig('grafico.svg', bbox_inches='tight')  # SVG escalable

plt.show()
```

### Mejores Pr√°cticas

1. **Siempre usar la interfaz orientada a objetos** para gr√°ficos complejos
2. **Configurar el estilo al inicio** del script
3. **Usar `plt.tight_layout()`** para evitar superposici√≥n
4. **Guardar gr√°ficos con `bbox_inches='tight'`** para recortar espacios en blanco
5. **Usar colores consistentes** y accesibles
6. **Agregar t√≠tulos y etiquetas descriptivas**
7. **Incluir leyendas cuando sea necesario**
8. **Usar `plt.show()`** al final para mostrar el gr√°fico

### Integraci√≥n con Pandas

```python
# Crear DataFrame de ejemplo
df = pd.DataFrame({
    'fecha': pd.date_range('2024-01-01', periods=100, freq='D'),
    'ventas': np.random.normal(100, 20, 100).cumsum(),
    'gastos': np.random.normal(80, 15, 100).cumsum()
})

# Gr√°fico usando Pandas con Matplotlib
fig, ax = plt.subplots(figsize=(12, 6))
df.plot(x='fecha', y=['ventas', 'gastos'], ax=ax, linewidth=2)
ax.set_title('Evoluci√≥n de Ventas y Gastos', fontsize=16, fontweight='bold')
ax.set_xlabel('Fecha', fontsize=14)
ax.set_ylabel('Monto ($)', fontsize=14)
ax.legend(fontsize=12)
ax.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```


## **Recursos Adicionales**
1. Documentaci√≥n oficial de Pandas: [Manejo de datos faltantes](https://pandas.pydata.org/docs/user_guide/missing_data.html) [1]
2. Libro: "Python for Data Analysis" de Wes McKinney (Cap. 10)
3. Tutorial avanzado: [DataCamp: Missing Data Techniques](https://www.datacamp.com/tutorial/techniques-to-handle-missing-data-values) [4]
4. Dataset pr√°ctico: [Air Quality Time Series](https://archive.ics.uci.edu/ml/datasets/Air+Quality)



Citations:
- [1] https://docs.kanaries.net/es/topics/Pandas/pandas-where
- [2] https://fastercapital.com/es/tema/manejo-de-datos-faltantes-y-valores-at%C3%ADpicos.html
- [3] https://www.growupcr.com/post/valores-nulos-python
- [4] https://www.datacamp.com/es/tutorial/techniques-to-handle-missing-data-values
- [5] https://www.codetodevs.com/como-utilizar-pandas-para-procesamiento-series-temporales/
- [6] https://www.codigofacilito.com/articulos/fechas-python
- [7] https://labex.io/es/tutorials/pandas-pandas-dataframe-asfreq-method-68584
- [8] https://www.youtube.com/watch?v=XKyX1ag4tnE
- [9] https://www.datacamp.com/tutorial/pandas-resample-asfreq
- [10] https://es.linkedin.com/advice/0/how-can-you-handle-missing-data-pandas-effectively-lilzc?lang=es
- [11] https://es.linkedin.com/advice/0/what-best-practices-using-groupby-pandas-time-series-xgbjf?lang=es
- [12] https://www.youtube.com/watch?v=ujODwjG3lv4
- [13] https://www.analyticslane.com/2021/08/12/pandas-contar-los-valores-nulos-en-dataframe/
- [14] https://certidevs.com/tutorial-pandas-operaciones-con-fechas
- [15] https://es.linkedin.com/pulse/manejo-de-datos-nulos-en-python-luis-felipe-castro-calder%C3%B3n
- [16] https://www.codetodevs.com/como-trabajar-con-datos-vacios-en-pandas/
- [17] https://www.freecodecamp.org/espanol/news/limpieza-de-datos-en-pandas-explicado-con-ejemplos/
- [18] https://interactivechaos.com/es/manual/tutorial-de-pandas/el-metodo-fillna
- [19] https://interactivechaos.com/es/manual/tutorial-de-pandas/el-metodo-dropna
- [20] https://www.freecodecamp.org/espanol/news/introduccion-a-las-series-de-pandas-con-ejemplos-intuitivos/
- [21] https://www.youtube.com/watch?v=CH7FWj3xcpo
- [22] https://joserzapata.github.io/courses/python-ciencia-datos/pandas/
- [23] https://www.youtube.com/watch?v=u5vfTWKLHe8
